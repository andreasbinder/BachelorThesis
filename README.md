# Preference-based Inverse Reinforcement Learning Approach for Robot Locomotion under Suboptimal Learning Conditions
**Bachelor's Thesis in Informatics**

## Abstract

Recent improvements in Reinforcement Learning (RL) have gained huge attention by both the media and academia. Additionally, with Neural Networks being universal approximators, it is possible to model complex reward functions which used to be intractable. Especially policy-gradient algorithms are popular among researchers because they can be applied on continuous, high-dimensional tasks, most notably OpenAI's Proximal Policy Optimization, which will be also used for this work. Policy-gradient methods have better convergence properties than traditional RL algorithms and can model the true distribution of actions quite well when provided with a proper reward function. This is the reason where the paradigm of Inverse Reinforcement Learning (IRL) comes into play. Given a policy, IRL tries to infer the underlying reward function. Most IRL algorithms suffer from the problem of not being able to extrapolate beyond their provided policy. This work aims to tackle this problem by using trajectories generated by a suboptimal policy which is used to deliver far better results compared to other state-of-the art approaches. We build on Daniel Brown's work on T-REX, which uses pairwise trajectory ranking to capture the intent of the agent and thus obtains very good results on standard Mujoco tasks and Atari games. We additionally investigate the impact of the loss function. Specifically, we analyze whether there are performance gains when choosing standard ranking loss that operates on a list of trajectories. Pair-wise ranking is only a special case of the list-wise ranking where the number of trajectories is set to two. 
The motivation to use suboptimal trajectories reflects the fact that generally they are easier to obtain and can be derived for most tasks relatively cheaply. In addition, it can be argued that the reward function is of higher quality since it mirrors the intention instead of plainly trying to explain the presented trajectories. 
We want to implement those ideas for a snake-like robot that can be simulated on the Mujoco environment. Those autonomous robots are used in catastrophic situation in terrain that is hardly accessible to human beings. For instance, it can be made use of at collapsed houses after an earthquake where it can help finding buried humans.


## Installation 

### Requirements

## Usage

## Author
Andreas Binder, Information Systems (B.Sc.), Technical University Munich


