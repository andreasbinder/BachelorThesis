# define hyperparameters for IRL training
reward_learning:
  num_nets: 1
  input_dim: 27
  split_ratio: 0.9
  hparams:
    lr: 0.00005 #0.00005
    epochs: 20 #10
    ranking_approach: 5
    dataset_size: 0

ppo:
  general:
    env_id: Mujoco-planar-snake-cars-angle-line-v1
    seed: 0
    log_dir: gym_mujoco_planar_snake/results/
  initial:
    create_trajectories: false # if false you need to provide training data
    trajectory_length: 50
    num_traj_per_episode: 10
    num_agents: 1 # 5
    num_timesteps: 1000000 # 1000000
    sfs: 10000 #10000
    save_checkpoints: true
  improved:
    validate_learned_reward: true
    num_agents: 1
    num_timesteps: 1000000 #800000
    sfs: 100000 #100000
    save_checkpoints: true
    ctrl_coeff: 0.2 #0.0  should prevent agent from taking too high action values


